{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67350748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment and api key\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import shutil\n",
    "import getpass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d34cd2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your OpenAI API key:\n",
      "✓ API key set successfully: sk-proj...Tr8A\n"
     ]
    }
   ],
   "source": [
    "# Prompt for OpenAI API key with password masking\n",
    "print(\"Please enter your OpenAI API key:\")\n",
    "openai_api_key = getpass.getpass(\"API Key: \")\n",
    "\n",
    "# Set as environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "# Verify it was set (show only first/last few characters for security)\n",
    "if openai_api_key:\n",
    "    masked_key = f\"{openai_api_key[:7]}...{openai_api_key[-4:]}\"\n",
    "    print(f\"✓ API key set successfully: {masked_key}\")\n",
    "else:\n",
    "    print(\"✗ No API key entered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19afc2d",
   "metadata": {},
   "source": [
    "### Only run this when necessary! as it will delete all existing data!  And will cost $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92f68af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ bevin_1631.html\n",
      "  Title: A briefe and short instruction of the art of musicke to teach how to make discan...\n",
      "  Author: Bevin, Elway, ca. 1554-1638.\n",
      "  Citation: \"A briefe and short instruction of the art of musicke to teach how to make discant, of all proportions that are in vse: very necessary for all such as are desirous to attaine to knowledge in the art; and may by practice, if they can sing, soone be able to compose three, foure, and five parts: and also to compose all sorts of canons that are usuall, by these directions of two or three parts in one, upon the plain-song. By Elvvay Bevin.\" In the digital collectionEarly English Books Online.https://name.umdl.umich.edu/A09578.0001.001. University of Michigan Library Digital Collections. Accessed December 28, 2025.\n",
      "  Pages: 64 | Chunks: 64\n",
      "✓ playford_1654.html\n",
      "  Title: A breefe introduction to the skill of musick for song & violl / by J.P.\n",
      "  Author: Playford, John, 1623-1686?\n",
      "  Citation: \"A breefe introduction to the skill of musick for song & violl / by J.P.\" In the digital collectionEarly English Books Online.https://name.umdl.umich.edu/A55042.0001.001. University of Michigan Library Digital Collections. Accessed December 28, 2025.\n",
      "  Pages: 38 | Chunks: 39\n",
      "✓ le_roy_1574.html\n",
      "  Title: A briefe and plaine instruction to set all musicke of eight diuers tunes in tabl...\n",
      "  Author: Le Roy, Adrian, ca. 1520-1598.\n",
      "  Citation: \"A briefe and plaine instruction to set all musicke of eight diuers tunes in tableture for the lute With a briefe instruction how to play on the lute by tablature, to conduct and dispose thy hand vnto the lute, with certaine easie lessons for that purpose. And also a third booke containing diuers new excellent tunes. All first written in French by Adrian Le Roy, and now translated into English by F. Ke. gentleman.\" In the digital collectionEarly English Books Online.https://name.umdl.umich.edu/A05334.0001.001. University of Michigan Library Digital Collections. Accessed December 28, 2025.\n",
      "  Pages: 184 | Chunks: 197\n",
      "✓ bathe_1596.html\n",
      "  Title: A briefe introduction to the skill of song concerning the practise, set forth by...\n",
      "  Author: Bathe, William, 1564-1614.\n",
      "  Citation: \"A briefe introduction to the skill of song concerning the practise, set forth by William Bathe gentleman. In which work is set downe X. sundry wayes of 2. parts in one vpon the plaine song. Also a table newly added of the companions of cleues, how one followeth another for the naming of notes: with other necessarie examples, to further the learner.\" In the digital collectionEarly English Books Online.https://name.umdl.umich.edu/A05729.0001.001. University of Michigan Library Digital Collections. Accessed December 28, 2025.\n",
      "  Pages: 51 | Chunks: 51\n",
      "✓ descartes_1653.html\n",
      "  Title: Renatus Des-Cartes excellent compendium of musick with necessary and judicious a...\n",
      "  Author: Descartes, René, 1596-1650.\n",
      "  Citation: \"Renatus Des-Cartes excellent compendium of musick with necessary and judicious animadversions thereupon / by a person of honour.\" In the digital collectionEarly English Books Online.https://name.umdl.umich.edu/A35748.0001.001. University of Michigan Library Digital Collections. Accessed December 28, 2025.\n",
      "  Pages: 112 | Chunks: 113\n",
      "✓ ornithiparcus_1609.html\n",
      "  Title: Andreas Ornithoparcus his Micrologus, or Introduction: containing the art of sin...\n",
      "  Author: Ornithoparchus, Andreas, 16th cent.\n",
      "  Citation: \"Andreas Ornithoparcus his Micrologus, or Introduction: containing the art of singing Digested into foure bookes. Not onely profitable, but also necessary for all that are studious of musicke. Also the dimension and perfect vse of the monochord, according to Guido Aretinus. By Iohn Douland lutenist, lute-player, and Bachelor of Musicke in both the Vniuersities. 1609.\" In the digital collectionEarly English Books Online Collections.https://name.umdl.umich.edu/A08534.0001.001. University of Michigan Library Digital Collections. Accessed December 28, 2025.\n",
      "  Pages: 102 | Chunks: 146\n",
      "✓ morley_1596.html\n",
      "  Title: A plaine and easie introduction to practicall musicke set downe in forme of a di...\n",
      "  Author: Morley, Thomas, 1557-1603?\n",
      "  Citation: \"A plaine and easie introduction to practicall musicke set downe in forme of a dialogue: deuided into three partes, the first teacheth to sing with all things necessary for the knowledge of pricktsong. The second treateth of descante and to sing two parts in one vpon a plainsong or ground, with other things necessary for a descanter. The third and last part entreateth of composition of three, foure, fiue or more parts with many profitable rules to that effect. With new songs of 2. 3. 4. and .5 [sic] parts. By Thomas Morley, Batcheler of musick, & of the gent. of hir Maiesties Royall Chapell.\" In the digital collectionEarly English Books Online.https://name.umdl.umich.edu/A07753.0001.001. University of Michigan Library Digital Collections. Accessed December 26, 2025.\n",
      "  Pages: 230 | Chunks: 364\n",
      "✓ robinson_1609.html\n",
      "  Title: New citharen lessons with perfect tunings of the same, from foure course of stri...\n",
      "  Author: Robinson, Thomas, fl. 1589-1609.\n",
      "  Citation: \"New citharen lessons with perfect tunings of the same, from foure course of strings to fourteene course, euen to trie the sharpest teeth of enuie, with lessons of all sortes, and methodicall instructions for all professors and practitioners of the citharen. By Thomas Robinson, student in all the seuen liberall sciences.\" In the digital collectionEarly English Books Online.https://name.umdl.umich.edu/A10856.0001.001. University of Michigan Library Digital Collections. Accessed December 28, 2025.\n",
      "  Pages: 98 | Chunks: 98\n",
      "✓ ravenscroft_1614.html\n",
      "  Title: A briefe discourse of the true (but neglected) vse of charact'ring the degrees, ...\n",
      "  Author: Ravenscroft, Thomas, 1592?-1635?\n",
      "  Citation: \"A briefe discourse of the true (but neglected) vse of charact'ring the degrees, by their perfection, imperfection, and diminution in measurable musicke, against the common practise and custome of these times Examples whereof are exprest in the harmony of 4. voyces, concerning the pleasure of 5. vsuall recreations. 1 Hunting, 2 hawking, 3 dauncing, 4 drinking, 5 enamouring. By Thomas Rauenscroft, Bachelor of Musicke.\" In the digital collectionEarly English Books Online.https://name.umdl.umich.edu/A10477.0001.001. University of Michigan Library Digital Collections. Accessed December 28, 2025.\n",
      "  Pages: 230 | Chunks: 234\n",
      "\n",
      "==================================================\n",
      "ChromaDB Processing Complete\n",
      "==================================================\n",
      "Files processed: 9\n",
      "Total pages: 1109\n",
      "Total chunks: 1306\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "# Initialize vector store\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"HTML_samples\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory='./chroma-db'\n",
    ")\n",
    "\n",
    "# Configure text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=300,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False\n",
    ")\n",
    "\n",
    "def extract_metadata(soup):\n",
    "    \"\"\"Extract metadata from the HTML record section.\"\"\"\n",
    "    metadata = {\n",
    "        'title': '',\n",
    "        'author': '',\n",
    "        'pub_info': '',\n",
    "        'citation': ''\n",
    "    }\n",
    "    \n",
    "    # Find the record dl element\n",
    "    record_dl = soup.find('dl', class_='record')\n",
    "    if not record_dl:\n",
    "        print(\"No record dl found.\")\n",
    "        return metadata\n",
    "    \n",
    "    # Extract title\n",
    "    title_div = record_dl.find('div', {'data-key': 'title'})\n",
    "    if title_div:\n",
    "        title_dd = title_div.find('dd')\n",
    "        if title_dd:\n",
    "            metadata['title'] = title_dd.get_text(strip=True)\n",
    "    \n",
    "    # Extract author\n",
    "    author_div = record_dl.find('div', {'data-key': 'author'})\n",
    "    if author_div:\n",
    "        author_dd = author_div.find('dd')\n",
    "        if author_dd:\n",
    "            metadata['author'] = author_dd.get_text(strip=True)\n",
    "    \n",
    "    # Extract publication info\n",
    "    pubinfo_div = record_dl.find('div', {'data-key': 'pubinfo'})\n",
    "    if pubinfo_div:\n",
    "        pubinfo_dds = pubinfo_div.find_all('dd')\n",
    "        pub_parts = [dd.get_text(strip=True) for dd in pubinfo_dds]\n",
    "        metadata['pub_info'] = ' '.join(pub_parts)\n",
    "    \n",
    "    # Extract citation - look specifically in the citation section\n",
    "    citation_dt = record_dl.find('dt', string='Cite this Item')\n",
    "    if citation_dt:\n",
    "        citation_dd = citation_dt.find_next('dd')\n",
    "        if citation_dd:\n",
    "            citation_span = citation_dd.find('span')\n",
    "            if citation_span:\n",
    "                metadata['citation'] = citation_span.get_text(strip=True)\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def get_document_title(soup, metadata):\n",
    "    \"\"\"Extract the overall document title from HTML or metadata.\"\"\"\n",
    "    # Use metadata title if available\n",
    "    if metadata.get('title'):\n",
    "        return metadata['title']\n",
    "    \n",
    "    # Fallback to HTML title tag\n",
    "    title_tag = soup.find('title')\n",
    "    if title_tag and title_tag.text.strip():\n",
    "        return title_tag.text.strip()\n",
    "    \n",
    "    # Try h1 or h2 for document title\n",
    "    h1 = soup.find('h1')\n",
    "    if h1:\n",
    "        return h1.text.strip()\n",
    "    \n",
    "    h2 = soup.find('h2')\n",
    "    if h2:\n",
    "        return h2.text.strip()\n",
    "    \n",
    "    return \"Untitled Document\"\n",
    "\n",
    "def extract_pages(soup):\n",
    "    \"\"\"Extract individual pages with their metadata from the HTML.\"\"\"\n",
    "    pages = []\n",
    "    \n",
    "    # Find all article elements that represent pages\n",
    "    articles = soup.find_all('article', class_='fullview-page')\n",
    "    \n",
    "    for article in articles:\n",
    "        # Extract page metadata from the h3 heading\n",
    "        page_heading = article.find('h3', class_='js-toc-ignore')\n",
    "        \n",
    "        if page_heading:\n",
    "            page_num = page_heading.get('data-p-num', 'Unknown')\n",
    "            page_label = page_heading.get('data-heading-label', f'Page {page_num}')\n",
    "            base = page_heading.get('data-base', '')\n",
    "        else:\n",
    "            page_num = 'Unknown'\n",
    "            page_label = 'Unknown Page'\n",
    "            base = ''\n",
    "        \n",
    "        # Extract text content from this page, removing script/style\n",
    "        for script in article([\"script\", \"style\"]):\n",
    "            script.decompose()\n",
    "        \n",
    "        # Get clean text from the page\n",
    "        text = article.get_text(separator=' ', strip=True)\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        if text.strip():\n",
    "            pages.append({\n",
    "                'text': text,\n",
    "                'page_number': page_num,\n",
    "                'page_label': page_label,\n",
    "                'base': base\n",
    "            })\n",
    "    \n",
    "    return pages\n",
    "\n",
    "def process_html_files(html_dir='html_source'):\n",
    "    \"\"\"Process all HTML files in the specified directory.\"\"\"\n",
    "    html_files = glob.glob(os.path.join(html_dir, '*.html'))\n",
    "    \n",
    "    if not html_files:\n",
    "        print(f\"No HTML files found in {html_dir}\")\n",
    "        return\n",
    "    \n",
    "    total_chunks = 0\n",
    "    total_pages = 0\n",
    "    \n",
    "    for filename in html_files:\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                html_content = f.read()\n",
    "            \n",
    "            # Parse HTML\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            \n",
    "            # Extract metadata from the record section\n",
    "            doc_metadata = extract_metadata(soup)\n",
    "            \n",
    "            # Get document-level title\n",
    "            doc_title = get_document_title(soup, doc_metadata)\n",
    "            \n",
    "            # Extract pages\n",
    "            pages = extract_pages(soup)\n",
    "            \n",
    "            if not pages:\n",
    "                print(f\"Warning: No pages found in {filename}\")\n",
    "                continue\n",
    "            \n",
    "            file_chunks = 0\n",
    "            \n",
    "            # Process each page separately\n",
    "            for page in pages:\n",
    "                # Create metadata for this page, combining document and page metadata\n",
    "                page_metadata = {\n",
    "                    \"document_title\": doc_title,\n",
    "                    \"title\": doc_metadata['title'],\n",
    "                    \"author\": doc_metadata['author'],\n",
    "                    \"pub_info\": doc_metadata['pub_info'],\n",
    "                    \"citation\": doc_metadata['citation'],\n",
    "                    \"page_number\": page['page_number'],\n",
    "                    \"page_label\": page['page_label'],\n",
    "                    \"base\": page['base'],\n",
    "                    \"source_file\": os.path.basename(filename)\n",
    "                }\n",
    "                \n",
    "                # Split page text into chunks\n",
    "                chunks = text_splitter.create_documents(\n",
    "                    texts=[page['text']],\n",
    "                    metadatas=[page_metadata]\n",
    "                )\n",
    "                \n",
    "                # Add chunks to vector store\n",
    "                vector_store.add_documents(documents=chunks)\n",
    "                \n",
    "                file_chunks += len(chunks)\n",
    "                total_chunks += len(chunks)\n",
    "            \n",
    "            total_pages += len(pages)\n",
    "            print(f'✓ {os.path.basename(filename)}')\n",
    "            print(f'  Title: {doc_metadata[\"title\"][:80]}...' if len(doc_metadata[\"title\"]) > 80 else f'  Title: {doc_metadata[\"title\"]}')\n",
    "            print(f'  Author: {doc_metadata[\"author\"]}')\n",
    "            print(f'  Citation: {doc_metadata[\"citation\"]}')\n",
    "            print(f'  Pages: {len(pages)} | Chunks: {file_chunks}')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error processing {filename}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    print(f'\\n{\"=\"*50}')\n",
    "    print(f'ChromaDB Processing Complete')\n",
    "    print(f'{\"=\"*50}')\n",
    "    print(f'Files processed: {len(html_files)}')\n",
    "    print(f'Total pages: {total_pages}')\n",
    "    print(f'Total chunks: {total_chunks}')\n",
    "\n",
    "def query_example(query_text, n_results=5):\n",
    "    \"\"\"Example function to query the vector store.\"\"\"\n",
    "    results = vector_store.similarity_search(query_text, k=n_results)\n",
    "    \n",
    "    print(f\"\\nQuery: '{query_text}'\")\n",
    "    print(f\"Found {len(results)} results:\\n\")\n",
    "    \n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"Result {i}:\")\n",
    "        print(f\"  Title: {doc.metadata.get('title', 'N/A')[:80]}...\")\n",
    "        print(f\"  Author: {doc.metadata.get('author', 'N/A')}\")\n",
    "        print(f\"  Page: {doc.metadata.get('page_label', 'N/A')}\")\n",
    "        print(f\"  Citation: {doc.metadata.get('citation', 'N/A')}...\")\n",
    "        print(f\"  Source: {doc.metadata.get('source_file', 'N/A')}\")\n",
    "        print(f\"  Content preview: {doc.page_content[:200]}...\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure the HTML directory exists\n",
    "    html_dir = 'html_source'\n",
    "    if not os.path.exists(html_dir):\n",
    "        print(f\"Error: Directory '{html_dir}' not found\")\n",
    "        print(f\"Please create the '{html_dir}' directory and add your HTML files\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Process files\n",
    "    process_html_files(html_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e3f2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
